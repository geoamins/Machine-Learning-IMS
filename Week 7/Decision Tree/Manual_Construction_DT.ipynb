{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's manually construct a decision tree using a small, simplified dataset to make the process straightforward. We'll focus on just two features to keep the example clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "<table border=\"1\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Weather</th>\n",
    "            <th>Temperature</th>\n",
    "            <th>Play?</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Sunny</td>\n",
    "            <td>Hot</td>\n",
    "            <td>No</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Sunny</td>\n",
    "            <td>Mild</td>\n",
    "            <td>No</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Overcast</td>\n",
    "            <td>Cool</td>\n",
    "            <td>Yes</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Rainy</td>\n",
    "            <td>Mild</td>\n",
    "            <td>Yes</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Rainy</td>\n",
    "            <td>Cool</td>\n",
    "            <td>Yes</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Rainy</td>\n",
    "            <td>Cool</td>\n",
    "            <td>No</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Compute the Entropy of the Root Node\n",
    "The root node includes all samples. Let's calculate its entropy: <br/>\n",
    "\n",
    "Total samples: 6<br/>\n",
    "Positive samples (Play? = Yes): 3<br/>\n",
    "Negative samples (Play? = No): 3<br/>\n",
    "The formula for entropy is:\n",
    "$$H(S) = -p^+ \\log_2(p^+) - p^- \\log_2(p^-)$$\n",
    "<br/>\n",
    "where:<br/>\n",
    "Given:\n",
    "\n",
    "$$\n",
    "p^+ = \\frac{\\text{Positive samples}}{\\text{Total samples}} = \\frac{3}{6} = 0.5\n",
    "$$\n",
    "\n",
    "$$\n",
    "p^- = \\frac{\\text{Negative samples}}{\\text{Total samples}} = \\frac{3}{6} = 0.5\n",
    "$$\n",
    "\n",
    "Entropy \\( H(S) \\) is calculated as:\n",
    "\n",
    "$$\n",
    "H(S) = -p^+ \\log_2(p^+) - p^- \\log_2(p^-)\n",
    "$$\n",
    "\n",
    "Substitute the values:\n",
    "\n",
    "$$\n",
    "H(S) = - (0.5) \\log_2(0.5) - (0.5) \\log_2(0.5)\n",
    "$$\n",
    "\n",
    "$$\n",
    "H(S) = - (0.5)(-1) - (0.5)(-1) = 1\n",
    "$$\n",
    "\n",
    "Thus, the entropy \\( H(S) = 1 \\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Calculate Information Gain for Each Feature. <br />\n",
    "Feature: Weather<br />\n",
    "The values for Weather are: Sunny, Overcast, Rainy.<br />\n",
    "\n",
    "Subsets for Weather:\n",
    "* Sunny:\n",
    "    * Total samples: 2\n",
    "    * Play? = No: 2\n",
    "    * Entropy:\n",
    "  \n",
    "  The entropy for the \"Sunny\" class is calculated as:\n",
    "\n",
    "$$\n",
    "H(S_{\\text{Sunny}}) = - (1) \\log_2(1)\n",
    "$$\n",
    "\n",
    "Since \\(\\log_2(1) = 0\\), we have:\n",
    "\n",
    "$$\n",
    "H(S_{\\text{Sunny}}) = 0\n",
    "$$\n",
    "* Overcast:\n",
    "    * Total samples: 1\n",
    "    * Play? = Yes: 1\n",
    "    * Entropy:\n",
    "  \n",
    "  The entropy for the \"Overcast\" class is calculated as:\n",
    "\n",
    "    $$\n",
    "    H(S_{\\text{Overcast}}) = - (1) \\log_2(1)\n",
    "    $$\n",
    "\n",
    "    Since \\(\\log_2(1) = 0\\), we have:\n",
    "\n",
    "    $$\n",
    "    H(S_{\\text{Overcast}}) = 0\n",
    "    $$\n",
    "\n",
    "  * Rainy:\n",
    "    * Total samples:3\n",
    "    * Play? = Yes: 2, Play? = No: 1\n",
    "    * Entropy:\n",
    "**Entropy for \"Rainy\" Weather**\n",
    "The entropy for \"Rainy\" is calculated as:\n",
    "\n",
    "$$\n",
    "H(S_{\\text{Rainy}}) = - \\frac{3}{6} \\log_2 \\left( \\frac{3}{6} \\right) - \\frac{3}{6} \\log_2 \\left( \\frac{3}{6} \\right) \\approx 0.918\n",
    "$$\n",
    "\n",
    "**Weighted Entropy for Weather**\n",
    "\n",
    "The weighted entropy for weather is calculated as:\n",
    "\n",
    "$$\n",
    "H(S_{\\text{Weather}}) = \\frac{2}{6} (0) + \\frac{1}{6} (0) + \\frac{3}{6} (0.918) = 0.459\n",
    "$$\n",
    "\n",
    "**Information Gain for Weather**\n",
    "\n",
    "The information gain for weather is calculated as:\n",
    "\n",
    "$$\n",
    "IG(S, \\text{Weather}) = H(S) - H(S_{\\text{Weather}}) = 1 - 0.459 = 0.541\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature: Temperature**\n",
    "The values for Temperature are: Hot, Mild, Cool.<br/>\n",
    "\n",
    "Subsets for Temperature:<br/>\n",
    "*   Hot:\n",
    "    *   Total Samples: 1\n",
    "    *   Play? = No: 1, Hot:0\n",
    "    *   Entropy: \n",
    "  $$\n",
    "H(S_{\\text{Hot}}) = - (1) \\log_2(1)\n",
    "$$\n",
    "\n",
    "Since \\(\\log_2(1) = 0\\), we have:\n",
    "\n",
    "$$\n",
    "H(S_{\\text{Hot}}) = 0\n",
    "$$\n",
    "\n",
    "* Mild:\n",
    "\n",
    "Total samples: 2 <br />\n",
    "Play? = Yes: 1, Play? = No: 1 <br />\n",
    "Entropy:<br />\n",
    "$$\n",
    "H(S_{\\text{Mild}}) = - \\frac{2}{4} \\log_2 \\left( \\frac{2}{4} \\right) - \\frac{2}{4} \\log_2 \\left( \\frac{2}{4} \\right)\n",
    "$$\n",
    "\n",
    "Since \\(\\log_2 \\left( \\frac{2}{4} \\right) = -1\\), we have:\n",
    "\n",
    "$$\n",
    "H(S_{\\text{Mild}}) = - \\frac{2}{4} (-1) - \\frac{2}{4} (-1) = 1\n",
    "$$\n",
    "\n",
    "* Cool:\n",
    "\n",
    "Total samples: 3 <br />\n",
    "Play? = Yes: 2, Play? = No: 1 <br />\n",
    "Entropy:\n",
    "$$\n",
    "H(S_{\\text{Cool}}) = - \\frac{3}{6} \\log_2 \\left( \\frac{3}{6} \\right) - \\frac{3}{6} \\log_2 \\left( \\frac{3}{6} \\right) \\approx 0.918\n",
    "$$\n",
    "\n",
    "**Weighted Entropy for Temperature**\n",
    "\n",
    "The weighted entropy for temperature is calculated as:\n",
    "$$\n",
    "H(S_{\\text{Temperature}}) = \\frac{1}{6} (0) + \\frac{2}{6} (1) + \\frac{3}{6} (0.918) = 0.639\n",
    "$$\n",
    "\n",
    "**Information Gain for Temperature**\n",
    "\n",
    "The information gain for temperature is calculated as:\n",
    "\n",
    "$$\n",
    "IG(S, \\text{Temperature}) = H(S) - H(S_{\\text{Temperature}}) = 1 - 0.639 = 0.361\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Choose the Best Feature for the Root Node**\n",
    "Information Gain for Weather: 0.541 <br/>\n",
    "Information Gain for Temperature: 0.361 <br/>\n",
    "Since Weather has the highest information gain, it becomes the root node.<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Split the Tree on Weather**\n",
    "* Branch: Sunny\n",
    "  * All samples are: No.\n",
    "  * Leaf node: No.\n",
    "* Branch: Overcast\n",
    "  * All samples are: Yes.\n",
    "  * Leaf node: Yes.\n",
    "* Branch: Rainy\n",
    "  * Remaining samples\n",
    "    <table border=\"1\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Weather</th>\n",
    "            <th>Temperature</th>\n",
    "            <th>Play?</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Rainy</td>\n",
    "            <td>Mild</td>\n",
    "            <td>Yes</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Rainy</td>\n",
    "            <td>Cool</td>\n",
    "            <td>Yes</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Rainy</td>\n",
    "            <td>Cool</td>\n",
    "            <td>No</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Repeat for the Rainy Subset**\n",
    "The Rainy subset still has mixed labels, so we calculate the information gain for splitting it further using Temperature.\n",
    "\n",
    "* Subset Entropy for Rainy (Root Node Entropy)\n",
    "  $$H(S_\\text{Rainy})=0.918$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split on Temperature (for Rainy):\n",
    "* Mild:\n",
    "  * Total samples: 1\n",
    "  * Play? = Yes: 1\n",
    "  * Entropy: 0\n",
    "* Cool:\n",
    "  * Total samples: 2\n",
    "  * Play? = Yes: 1, Play? = No: 1\n",
    "  * Entropy: 1\n",
    "Weighted entropy for Temperature:\n",
    "$$\n",
    "H(S_{\\text{Rainy}, \\text{Temperature}}) = \\frac{1}{3} (0) + \\frac{2}{3} (1) = 0.667\n",
    "$$\n",
    "\n",
    "**Information Gain for Temperature (Rainy subset)**\n",
    "\n",
    "The information gain for the \"Rainy\" subset with respect to temperature is calculated as:\n",
    "$$\n",
    "IG(S_{\\text{Rainy}}, \\text{Temperature}) = H(S_{\\text{Rainy}}) - H(S_{\\text{Rainy}, \\text{Temperature}}) = 0.918 - 0.667 = 0.251\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Final Decision Tree**\n",
    "\n",
    "The final decision tree based on the given dataset with the selected features and their corresponding information gain values is shown below:<br />\n",
    "\n",
    "<img src=\"manual_decision_tree.png\">\n",
    "\n",
    "Since the labels are mixed, it indicates that we cannot make a pure decision (e.g., not all samples are Yes or No)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
